syntax = "proto3";

package orchion.v1;

option go_package = "github.com/Orchion/Orchion/shared/proto/v1;v1";

// --- Messages ---

message Capabilities {
  string cpu = 1;
  string memory = 2;
  string os = 3;
  string gpu_type = 4;
  string gpu_vram_total = 5;
  string gpu_vram_available = 6;
  string power_usage = 7;
}

message Node {
  string id = 1;
  string hostname = 2;
  Capabilities capabilities = 3;
  int64 last_seen_unix = 4;
  string agent_address = 5; // gRPC address for NodeAgent service (e.g., "hostname:50052")
}

// --- RPC Requests/Responses ---

message RegisterNodeRequest {
  Node node = 1;
}

message RegisterNodeResponse {}

message HeartbeatRequest {
  string node_id = 1;
}

message HeartbeatResponse {}

message UpdateNodeRequest {
  string node_id = 1;
  Capabilities capabilities = 2;
}

message UpdateNodeResponse {}

message ListNodesRequest {}

message ListNodesResponse {
  repeated Node nodes = 1;
}

// --- Logging Messages ---

enum LogLevel {
  LOG_LEVEL_UNSPECIFIED = 0;
  LOG_LEVEL_DEBUG = 1;
  LOG_LEVEL_INFO = 2;
  LOG_LEVEL_WARN = 3;
  LOG_LEVEL_ERROR = 4;
}

message LogEntry {
  string id = 1;
  int64 timestamp = 2;  // Unix timestamp in milliseconds
  LogLevel level = 3;
  string source = 4;    // Component/source that generated the log (e.g., "orchestrator", "node-agent:node123")
  string message = 5;
  map<string, string> fields = 6;  // Structured logging fields
}

message StreamLogsRequest {
  // Empty for now - could add filtering by node, level, time range later
}

message StreamLogsResponse {
  LogEntry entry = 1;
}

// --- LLM API Messages ---

message ChatMessage {
  string role = 1;    // "system", "user", "assistant"
  string content = 2;
}

message ChatCompletionRequest {
  string model = 1;
  repeated ChatMessage messages = 2;
  float temperature = 3;
  bool stream = 4;
  int32 max_tokens = 5;
}

message ChatChoice {
  int32 index = 1;
  ChatMessage message = 2;
  string finish_reason = 3;  // "stop", "length", etc.
}

message ChatCompletionResponse {
  string id = 1;
  string model = 2;
  repeated ChatChoice choices = 3;
  int64 created = 4;
  string object = 5;  // "chat.completion" or "chat.completion.chunk"
}

message EmbeddingRequest {
  string model = 1;
  repeated string input = 2;
}

message Embedding {
  repeated float embedding = 1;
  int32 index = 2;
}

message EmbeddingResponse {
  string model = 1;
  repeated Embedding data = 2;
  string object = 3;  // "list"
  int32 usage_prompt_tokens = 4;
}

// --- Job Messages ---

enum JobType {
  JOB_TYPE_UNSPECIFIED = 0;
  JOB_TYPE_CHAT_COMPLETION = 1;
  JOB_TYPE_EMBEDDINGS = 2;
}

enum JobStatus {
  JOB_STATUS_UNSPECIFIED = 0;
  JOB_STATUS_PENDING = 1;
  JOB_STATUS_ASSIGNED = 2;
  JOB_STATUS_RUNNING = 3;
  JOB_STATUS_COMPLETED = 4;
  JOB_STATUS_FAILED = 5;
}

message SubmitJobRequest {
  string job_id = 1;
  JobType job_type = 2;
  bytes payload = 3;  // Serialized request (ChatCompletionRequest or EmbeddingRequest)
}

message SubmitJobResponse {
  string job_id = 1;
  JobStatus status = 2;
}

message GetJobStatusRequest {
  string job_id = 1;
}

message GetJobStatusResponse {
  string job_id = 1;
  JobStatus status = 2;
  string assigned_node = 3;
  string error_message = 4;
  bytes result = 5;  // Serialized response if completed
}

// --- Service ---

service Orchestrator {
  rpc RegisterNode(RegisterNodeRequest) returns (RegisterNodeResponse);
  rpc UpdateNode(UpdateNodeRequest) returns (UpdateNodeResponse);
  rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse);
  rpc ListNodes(ListNodesRequest) returns (ListNodesResponse);
  rpc SubmitJob(SubmitJobRequest) returns (SubmitJobResponse);
  rpc GetJobStatus(GetJobStatusRequest) returns (GetJobStatusResponse);
}

// OrchionLLM service for OpenAI-compatible API
service OrchionLLM {
  rpc ChatCompletion(ChatCompletionRequest) returns (stream ChatCompletionResponse);
  rpc Embeddings(EmbeddingRequest) returns (EmbeddingResponse);
}

// NodeAgent service exposed by node agents for inference
service NodeAgent {
  rpc ChatCompletion(ChatCompletionRequest) returns (stream ChatCompletionResponse);
  rpc Embeddings(EmbeddingRequest) returns (EmbeddingResponse);
}

// LogStreamer service for centralized logging
service LogStreamer {
  rpc StreamLogs(StreamLogsRequest) returns (stream StreamLogsResponse);
}
